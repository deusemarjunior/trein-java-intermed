# Dia 7 - Podman, Cloud Readiness e Observabilidade

**Dura√ß√£o**: 5 horas  
**Objetivo**: "Na minha m√°quina funciona" n√£o √© desculpa ‚Äî containerizar a aplica√ß√£o com Podman (multi-stage build), orquestrar com Podman Compose, adicionar observabilidade com Spring Actuator e logs estruturados (JSON + MDC), e introduzir conceitos de CI/CD.

> **Pr√©-requisito**: Dias 1-6 conclu√≠dos (especialmente Dia 6 ‚Äî Persist√™ncia Avan√ßada e Mensageria). Podman Desktop instalado e rodando.

---

## üéØ Agenda do Dia

| Hor√°rio | Dura√ß√£o | T√≥pico | Tipo |
|---------|---------|--------|------|
| 09:00 - 09:15 | 15min | Recap Dia 6 e Introdu√ß√£o ao Dia 7 | Discuss√£o |
| 09:15 - 09:45 | 30min | Podman ‚Äî Containerfile, Instru√ß√µes e Conceitos | Te√≥rico |
| 09:45 - 10:15 | 30min | Multi-stage Build e .containerignore | Te√≥rico |
| 10:15 - 10:45 | 30min | Podman Compose ‚Äî App + Infraestrutura Completa | Te√≥rico |
| 10:45 - 11:00 | 15min | ‚òï Coffee Break | - |
| 11:00 - 11:30 | 30min | Spring Actuator ‚Äî Health, Metrics, Info | Te√≥rico |
| 11:30 - 12:00 | 30min | Logs Estruturados ‚Äî Logback JSON + MDC | Te√≥rico |
| 12:00 - 13:00 | 1h | üçΩÔ∏è Almo√ßo | - |
| 13:00 - 13:20 | 20min | Observabilidade e CI/CD (Conceitual) | Te√≥rico |
| 13:20 - 13:50 | 30min | Walkthrough `07-podman-actuator-demo` | Demo |
| 13:50 - 15:30 | 1h40 | Exerc√≠cio `07-employee-api-production` (TODOs 1-4) | Hands-on |
| 15:30 - 16:30 | 1h | Exerc√≠cio `07-employee-api-production` (TODOs 5-7) | Hands-on |
| 16:30 - 17:00 | 30min | Review: imagem < 100MB, Actuator respondendo, logs JSON | Discuss√£o |

---

## üì¶ Material Necess√°rio (Checklist Instrutor)

### Software
- [ ] JDK 21 instalado
- [ ] Maven 3.8+
- [ ] IDE com suporte a Java (IntelliJ ou VS Code)
- [ ] Podman Desktop rodando
- [ ] _(Opcional)_ Postman ou extens√£o REST Client no VS Code

### Prepara√ß√£o
- [ ] Executar `podman compose up` no projeto `07-podman-actuator-demo` e verificar:
  - [ ] PostgreSQL acess√≠vel na porta 5432
  - [ ] RabbitMQ Management UI em http://localhost:15672 (guest/guest)
  - [ ] Redis acess√≠vel na porta 6379
  - [ ] App respondendo em http://localhost:8080/api/products
  - [ ] Actuator respondendo em http://localhost:8080/actuator/health
- [ ] Projeto `07-podman-actuator-demo` rodando com logs JSON no container
- [ ] Projeto `07-employee-api-production` com TODOs prontos e depend√™ncias configuradas

---

## üìã Conte√∫do Program√°tico

---

### 1. Podman ‚Äî Containerizando a Aplica√ß√£o

#### Por que Podman?

O cl√°ssico "na minha m√°quina funciona" acontece porque ambientes s√£o diferentes: vers√£o do Java, vari√°veis de ambiente, servi√ßos rodando. **Podman resolve isso empacotando tudo em um container reprodut√≠vel.**

```
Sem Podman:    Dev (Java 21) ‚Üí Staging (Java 17) ‚Üí Prod (Java 11) ‚Üí üí• FALHA
Com Podman:    Dev (Container) ‚Üí Staging (Container) ‚Üí Prod (Container) ‚Üí ‚úÖ FUNCIONA
```

#### Containerfile ‚Äî A Receita

O **Containerfile** √© a receita para construir uma imagem Podman. Cada instru√ß√£o cria uma **camada (layer)**:

```podmanfile
# Imagem base
FROM eclipse-temurin:21-jdk-alpine

# Diret√≥rio de trabalho dentro do container
WORKDIR /app

# Copiar arquivos do projeto
COPY target/*.jar app.jar

# Porta que a app exp√µe
EXPOSE 8080

# Comando para executar a aplica√ß√£o
ENTRYPOINT ["java", "-jar", "app.jar"]
```

#### Instru√ß√µes Principais

| Instru√ß√£o | O que faz | Exemplo |
|-----------|-----------|---------|
| `FROM` | Imagem base | `FROM eclipse-temurin:21-jdk-alpine` |
| `WORKDIR` | Define diret√≥rio de trabalho | `WORKDIR /app` |
| `COPY` | Copia arquivos para dentro da imagem | `COPY target/*.jar app.jar` |
| `RUN` | Executa comando durante o build | `RUN mvn package -DskipTests` |
| `EXPOSE` | Documenta a porta (n√£o abre de verdade) | `EXPOSE 8080` |
| `ENTRYPOINT` | Comando executado ao iniciar o container | `ENTRYPOINT ["java", "-jar", "app.jar"]` |
| `ENV` | Define vari√°veis de ambiente | `ENV SPRING_PROFILES_ACTIVE=prod` |
| `ARG` | Vari√°vel de build-time | `ARG JAR_FILE=target/*.jar` |

> **EXPOSE** apenas documenta a porta ‚Äî para acessar externamente, use `-p 8080:8080` no `podman run` ou `ports:` no Compose.

#### Cache de Layers

Podman **cacheia cada layer** ‚Äî se uma instru√ß√£o n√£o mudou, usa o cache. A **ordem importa**:

```podmanfile
# ‚ùå Ruim: qualquer mudan√ßa no c√≥digo invalida o cache do mvn package
COPY . .
RUN mvn package -DskipTests

# ‚úÖ Bom: mudou o pom.xml ‚Üí recache deps. Mudou apenas src ‚Üí s√≥ rebuild
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src/ src/
RUN mvn package -DskipTests
```

---

### 2. Multi-stage Build ‚Äî Imagem de Produ√ß√£o

#### O Problema das Imagens Grandes

```podmanfile
# Imagem com JDK + Maven + sources + target = ~800MB üò±
FROM maven:3.9-eclipse-temurin-21
COPY . .
RUN mvn package -DskipTests
ENTRYPOINT ["java", "-jar", "target/app.jar"]
```

Para rodar a aplica√ß√£o, **n√£o precisamos do Maven, JDK nem do c√≥digo-fonte** ‚Äî s√≥ do JAR e do JRE.

#### A Solu√ß√£o: Multi-stage Build

```podmanfile
# ‚îÄ‚îÄ Stage 1: BUILD ‚îÄ‚îÄ
FROM eclipse-temurin:21-jdk-alpine AS build
WORKDIR /app
COPY pom.xml .
COPY .mvn/ .mvn/
COPY mvnw .
RUN chmod +x mvnw && ./mvnw dependency:go-offline
COPY src/ src/
RUN ./mvnw clean package -DskipTests

# ‚îÄ‚îÄ Stage 2: RUNTIME ‚îÄ‚îÄ
FROM eclipse-temurin:21-jre-alpine
WORKDIR /app
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
COPY --from=build /app/target/*.jar app.jar
USER appuser
EXPOSE 8080
HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
    CMD wget --quiet --tries=1 --spider http://localhost:8080/actuator/health || exit 1
ENTRYPOINT ["java", "-jar", "app.jar"]
```

| Aspecto | Sem multi-stage | Com multi-stage |
|---------|----------------|-----------------|
| **Tamanho** | ~800MB | ~80MB |
| **Seguran√ßa** | JDK + Maven + sources expostos | Apenas JRE + JAR |
| **Superf√≠cie de ataque** | Grande | M√≠nima |

#### .containerignore

Assim como `.gitignore`, o `.containerignore` **exclui arquivos do contexto de build**:

```
target/
.git/
.idea/
*.iml
.env
podman-compose*.yml
README.md
*.md
.vscode/
```

> **Sem .containerignore**: o `COPY . .` copia `.git/` (pode ter 100MB+), `target/` e tudo mais para dentro do build context.

---

### 3. Podman Compose ‚Äî Orquestrando a Stack

Uma aplica√ß√£o de verdade n√£o roda sozinha ‚Äî precisa de banco de dados, cache, fila de mensagens. **Podman Compose** orquestra tudo em um arquivo.

#### Anatomia do podman-compose.yml

```yaml
services:
  app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/mydb
      - SPRING_REDIS_HOST=redis
      - SPRING_RABBITMQ_HOST=rabbitmq
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d mydb"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  pgdata:

networks:
  default:
    name: myapp-network
```

#### Conceitos-Chave do Compose

| Conceito | O que faz | Por qu√™ |
|----------|-----------|---------|
| `depends_on + condition` | Espera o servi√ßo estar healthy | Evita que a app suba antes do banco |
| `healthcheck` | Verifica se o servi√ßo est√° pronto | `pg_isready`, `redis-cli ping`, etc. |
| `volumes` | Persiste dados entre restarts | Dados do PostgreSQL n√£o s√£o perdidos |
| `networks` | Isola comunica√ß√£o entre containers | Containers se comunicam por nome do servi√ßo |
| `environment` | Injeta vari√°veis | Externalizar configura√ß√£o |

#### Comandos Essenciais

```bash
podman compose up -d                  # Sobe tudo em background
podman compose up --build -d          # Rebuild + sobe
podman compose down                   # Para e remove containers
podman compose logs -f app            # Logs da app em tempo real
podman compose ps                     # Status dos containers
podman compose exec app sh            # Shell dentro do container
```

---

### 4. Spring Actuator ‚Äî Observabilidade Nativa

**Spring Actuator** adiciona endpoints de monitoramento √† aplica√ß√£o sem escrever c√≥digo ‚Äî essencial para opera√ß√µes em produ√ß√£o.

#### Configura√ß√£o

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,env,flyway
  endpoint:
    health:
      show-details: always
  info:
    env:
      enabled: true
```

#### Endpoints Principais

| Endpoint | O que retorna |
|----------|---------------|
| `/actuator/health` | Status de sa√∫de (UP/DOWN) de cada componente |
| `/actuator/info` | Informa√ß√µes da aplica√ß√£o (nome, vers√£o, etc.) |
| `/actuator/metrics` | Lista de m√©tricas dispon√≠veis |
| `/actuator/metrics/jvm.memory.used` | Mem√≥ria JVM em uso |
| `/actuator/metrics/http.server.requests` | M√©tricas de requisi√ß√µes HTTP |
| `/actuator/env` | Vari√°veis de ambiente e propriedades |
| `/actuator/flyway` | Status das migrations executadas |

#### Custom Health Indicator

Para verificar depend√™ncias externas (RabbitMQ, servi√ßos externos):

```java
@Component
public class RabbitMQHealthIndicator implements HealthIndicator {

    private final RabbitTemplate rabbitTemplate;

    @Override
    public Health health() {
        try {
            rabbitTemplate.execute(channel -> {
                channel.queueDeclarePassive("employee-notifications");
                return null;
            });
            return Health.up()
                    .withDetail("queue", "employee-notifications")
                    .withDetail("status", "reachable")
                    .build();
        } catch (Exception e) {
            return Health.down()
                    .withDetail("error", e.getMessage())
                    .build();
        }
    }
}
```

Resposta do `/actuator/health`:
```json
{
  "status": "UP",
  "components": {
    "db": { "status": "UP" },
    "diskSpace": { "status": "UP" },
    "rabbitMQ": { "status": "UP", "details": { "queue": "employee-notifications" } },
    "redis": { "status": "UP" }
  }
}
```

> **Em produ√ß√£o**: Kubernetes usa `/actuator/health/liveness` e `/actuator/health/readiness` para decidir se o pod est√° saud√°vel.

---

### 5. Logs Estruturados ‚Äî JSON com Logback e MDC

#### Por que texto puro n√£o escala?

```
# Log em texto puro ‚Äî dif√≠cil de parsear e filtrar
2024-01-15 10:30:45.123 INFO  [http-nio-8080-exec-1] c.e.service.EmployeeService - Criando funcion√°rio: Ana Silva
```

Para 1 servidor √© leg√≠vel. Para **50 servidores** com **milhares de logs/segundo**, √© imposs√≠vel buscar e correlacionar.

#### Logs em JSON ‚Äî Machine-readable

```json
{
  "@timestamp": "2024-01-15T10:30:45.123Z",
  "level": "INFO",
  "logger_name": "c.e.service.EmployeeService",
  "message": "Criando funcion√°rio: Ana Silva",
  "traceId": "abc-123-def",
  "method": "POST",
  "uri": "/api/employees",
  "thread_name": "http-nio-8080-exec-1"
}
```

> **JSON √© parse√°vel por m√°quinas** ‚Äî Elasticsearch, Datadog, CloudWatch conseguem indexar, buscar e criar dashboards automaticamente.

#### Logback + LogstashEncoder

```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- Profile DEV: texto leg√≠vel para humanos -->
    <springProfile name="default,dev">
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <encoder>
                <pattern>%d{HH:mm:ss.SSS} [%X{traceId:-}] %-5level %logger{36} - %msg%n</pattern>
            </encoder>
        </appender>
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
        </root>
    </springProfile>

    <!-- Profile PROD: JSON para ferramentas de observabilidade -->
    <springProfile name="prod">
        <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
        </appender>
        <root level="INFO">
            <appender-ref ref="JSON"/>
        </root>
    </springProfile>
</configuration>
```

```xml
<!-- pom.xml -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

#### MDC ‚Äî Mapped Diagnostic Context

O **MDC** permite injetar informa√ß√µes de contexto (traceId, userId, requestId) que aparecem **automaticamente em todos os logs** daquela thread:

```java
@Component
public class MdcFilter extends OncePerRequestFilter {

    @Override
    protected void doFilterInternal(HttpServletRequest request,
                                     HttpServletResponse response,
                                     FilterChain filterChain) throws ServletException, IOException {
        try {
            MDC.put("traceId", UUID.randomUUID().toString().substring(0, 8));
            MDC.put("method", request.getMethod());
            MDC.put("uri", request.getRequestURI());
            filterChain.doFilter(request, response);
        } finally {
            MDC.clear();  // SEMPRE limpar para evitar vazamento entre threads
        }
    }
}
```

Com MDC, todos os logs de uma mesma requisi√ß√£o t√™m o mesmo `traceId`:

```json
{"traceId": "abc-123", "message": "Buscando funcion√°rio id=42"}
{"traceId": "abc-123", "message": "Funcion√°rio encontrado: Jo√£o"}
{"traceId": "abc-123", "message": "Cache hit para departamento id=3"}
```

> **Correla√ß√£o**: filtrando por `traceId=abc-123` voc√™ v√™ TODO o fluxo daquela requisi√ß√£o.

---

### 6. Observabilidade em Produ√ß√£o (Conceitual)

#### O que √© Observabilidade?

Observabilidade √© a capacidade de **entender o estado interno de um sistema** a partir dos dados que ele exp√µe externamente. Em um cen√°rio com dezenas de microsservi√ßos rodando em containers, √© imposs√≠vel fazer SSH em cada m√°quina para investigar problemas. Observabilidade resolve isso com **dados estruturados e centralizados**.

> **Monitoramento** responde "o sistema est√° funcionando?"  
> **Observabilidade** responde "por que o sistema est√° lento/falhando e onde exatamente?"

#### Os 3 Pilares da Observabilidade

Observabilidade se sustenta em **tr√™s pilares complementares** ‚Äî cada um responde a uma pergunta diferente:

```mermaid
graph TB
    O["üî≠ Observabilidade"] --> M["üìä M√©tricas"]
    O --> L["üìù Logs"]
    O --> T["üîó Traces"]
    M --> MQ["O QU√ä est√° acontecendo?<br/>Dados num√©ricos agregados"]
    L --> LQ["POR QU√ä aconteceu?<br/>Eventos detalhados"]
    T --> TQ["ONDE aconteceu?<br/>Caminho da requisi√ß√£o"]
```

---

#### Pilar 1: M√©tricas (Metrics)

**M√©tricas** s√£o dados num√©ricos agregados ao longo do tempo. Respondem √† pergunta **"o qu√™ est√° acontecendo agora?"** de forma quantitativa.

| Tipo de M√©trica | O que mede | Exemplo |
|-----------------|-----------|--------|
| **Counter** | Contagem acumulativa (s√≥ cresce) | Total de requisi√ß√µes HTTP, erros 500 |
| **Gauge** | Valor pontual (sobe e desce) | Mem√≥ria em uso, threads ativas, conex√µes no pool |
| **Histogram** | Distribui√ß√£o de valores | Lat√™ncia p50/p95/p99, tamanho de payloads |
| **Timer** | Dura√ß√£o + contagem | Tempo de resposta por endpoint |

**Exemplos pr√°ticos:**

```
http_server_requests_total{method="GET", uri="/api/employees", status="200"} = 15432
http_server_requests_duration_seconds{quantile="0.99"} = 0.250
jvm_memory_used_bytes{area="heap"} = 134217728
hikaricp_connections_active = 8
```

**Ferramentas:**
- **Micrometer**: biblioteca Java que instrumenta a aplica√ß√£o (j√° integrada no Spring Actuator)
- **Prometheus**: coleta e armazena m√©tricas em s√©ries temporais (pull-based, scrape a cada 15s)
- **Grafana**: visualiza√ß√£o com dashboards e alertas

**Fluxo t√≠pico:**
```
Spring Boot (Micrometer) ‚Üí /actuator/prometheus ‚Üí Prometheus (scrape) ‚Üí Grafana (dashboard)
```

**Quando usar m√©tricas:**
- Dashboards de sa√∫de do sistema (RED: Rate, Errors, Duration)
- Alertas autom√°ticos (ex.: lat√™ncia p99 > 2s ‚Üí alerta no Slack)
- Capacity planning (uso de CPU/mem√≥ria ao longo de semanas)
- SLIs/SLOs (99.9% de requests com status 2xx)

> **M√©tricas dizem que algo est√° errado, mas n√£o dizem por qu√™.** Para isso, usamos logs.

---

#### Pilar 2: Logs

**Logs** s√£o registros de eventos discretos que aconteceram na aplica√ß√£o. Respondem √† pergunta **"por qu√™ algo aconteceu?"** com contexto detalhado.

```
// Sem estrutura (texto puro) ‚Äî dif√≠cil de filtrar em escala
2024-01-15 10:30:45 ERROR EmployeeService - Funcion√°rio n√£o encontrado: id=42

// Estruturado (JSON) ‚Äî parse√°vel por m√°quinas
{"@timestamp":"2024-01-15T10:30:45Z", "level":"ERROR", "traceId":"abc123",
 "logger":"EmployeeService", "message":"Funcion√°rio n√£o encontrado", "employeeId":42}
```

**N√≠veis de log e quando usar:**

| N√≠vel | Quando usar | Exemplo |
|-------|------------|--------|
| `ERROR` | Algo falhou e precisa de aten√ß√£o | Exce√ß√£o n√£o tratada, servi√ßo externo fora do ar |
| `WARN` | Situa√ß√£o inesperada mas contorn√°vel | Retry de conex√£o, fallback ativado, cache miss repetido |
| `INFO` | Eventos de neg√≥cio relevantes | Funcion√°rio criado, pedido processado, login efetuado |
| `DEBUG` | Detalhes t√©cnicos para investiga√ß√£o | Query SQL executada, payload recebido, estado interno |
| `TRACE` | Detalhamento m√°ximo (raramente usado) | Cada itera√ß√£o de loop, cada byte lido |

**Boas pr√°ticas de logging:**

```java
// ‚úÖ Bom: informa√ß√£o contextual e estruturada
log.info("Funcion√°rio criado com sucesso: id={}, nome={}", employee.getId(), employee.getName());
log.error("Erro ao buscar funcion√°rio: id={}", id, exception);

// ‚ùå Ruim: concatena√ß√£o, sem contexto, sem exce√ß√£o
log.info("Funcion√°rio criado");
log.error("Erro: " + e.getMessage());
```

**Ferramentas:**
- **ELK Stack**: Elasticsearch (armazena) + Logstash (processa) + Kibana (visualiza)
- **Datadog Logs**: coleta, indexa√ß√£o e busca em tempo real
- **AWS CloudWatch Logs**: integrado com servi√ßos AWS
- **Loki (Grafana)**: logs otimizados para labels (como Prometheus para logs)

**Fluxo t√≠pico:**
```
App (JSON stdout) ‚Üí Filebeat/Fluentd (coleta) ‚Üí Elasticsearch (indexa) ‚Üí Kibana (busca/dashboard)
```

> **Logs em JSON s√£o obrigat√≥rios em produ√ß√£o.** Texto puro n√£o pode ser indexado nem filtrado em escala.

---

#### Pilar 3: Traces (Rastreamento Distribu√≠do)

**Traces** registram o **caminho completo de uma requisi√ß√£o** atrav√©s de m√∫ltiplos servi√ßos. Respondem √† pergunta **"onde no fluxo o problema aconteceu?"**

Em uma arquitetura de microsservi√ßos, uma √∫nica requisi√ß√£o do usu√°rio pode passar por 5, 10 ou 20 servi√ßos. Sem tracing, √© imposs√≠vel saber **qual servi√ßo demorou** ou **onde a falha ocorreu**.

```mermaid
graph LR
    U["üë§ Usu√°rio"] --> GW["API Gateway<br/>12ms"]
    GW --> A["Employee Service<br/>45ms"]
    A --> DB[("PostgreSQL<br/>8ms")]
    A --> B["Notification Service<br/>1200ms ‚ö†Ô∏è"]
    B --> SMTP["SMTP Server<br/>1150ms üî¥"]
    A --> C["Cache Service<br/>3ms"]
    C --> RD[("Redis<br/>1ms")]
```

> Neste exemplo, o trace mostra que o problema est√° no **SMTP Server** (1150ms) ‚Äî sem tracing, voc√™ investigaria todos os servi√ßos.

**Conceitos-chave:**

| Conceito | O que √© | Exemplo |
|----------|---------|---------|
| **Trace** | O caminho completo de uma requisi√ß√£o (fim-a-fim) | Usu√°rio ‚Üí Gateway ‚Üí Service A ‚Üí DB ‚Üí resposta |
| **Span** | Uma opera√ß√£o individual dentro do trace | "Query ao PostgreSQL" (dura√ß√£o: 8ms) |
| **TraceId** | Identificador √∫nico que conecta todos os spans | `abc-123-def-456` (propagado entre servi√ßos) |
| **SpanId** | Identificador de cada opera√ß√£o individual | `span-001`, `span-002`, etc. |
| **Parent Span** | Span que iniciou o span atual | Employee Service √© parent do Database span |

**Como funciona a propaga√ß√£o:**

```
‚îå‚îÄ‚îÄ‚îÄ Trace: abc-123 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ Span 1: API Gateway (12ms) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ Span 2: Employee Service (45ms) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ Span 3: PostgreSQL Query (8ms) ‚îÄ‚îÄ‚îê                 ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ Span 4: Notification Service (1200ms) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ Span 5: SMTP Send (1150ms) üî¥ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

O `traceId` √© passado entre servi√ßos via **HTTP headers** (`X-Trace-Id`, `traceparent`). Cada servi√ßo cria seus pr√≥prios spans e os associa ao mesmo trace.

**Ferramentas:**
- **Zipkin**: tracing distribu√≠do open-source (Twitter)
- **Jaeger**: tracing distribu√≠do open-source (Uber)
- **AWS X-Ray**: integrado com servi√ßos AWS
- **Datadog APM**: tracing + m√©tricas + logs correlacionados
- **OpenTelemetry**: padr√£o aberto que unifica m√©tricas, logs e traces

> **No Spring Boot**: o Micrometer Tracing (antigo Spring Cloud Sleuth) injeta `traceId` e `spanId` automaticamente nos logs e headers HTTP.

---

#### Como os 3 Pilares se Complementam

| Situa√ß√£o | M√©trica detecta | Log explica | Trace localiza |
|----------|----------------|-------------|----------------|
| API lenta | Lat√™ncia p99 subiu de 200ms ‚Üí 2s | `WARN: Connection pool exhausted` | Span mostra que DB query levou 1.8s |
| Erros 500 | Taxa de erro subiu para 5% | `ERROR: NullPointerException at line 42` | Trace mostra que falha √© no Service B |
| Fila parada | Consumer lag = 10.000 msgs | `ERROR: RabbitMQ connection refused` | Trace mostra timeout no broker |

```
1. Alerta da M√âTRICA:  "Lat√™ncia p99 > 2s"     ‚Üí Investiga com LOGS
2. LOG diz:            "Timeout no PostgreSQL"  ‚Üí Investiga com TRACE
3. TRACE mostra:       "Query SELECT * FROM orders sem index levou 1.8s"
4. Solu√ß√£o:            CREATE INDEX idx_orders_status ON orders(status);
```

> **Observabilidade n√£o √© sobre ter dashboards bonitos** ‚Äî √© sobre **reduzir o tempo de investiga√ß√£o** (MTTR) quando algo d√° errado em produ√ß√£o.

#### Ferramentas de Mercado ‚Äî Resumo

| Stack | M√©tricas | Logs | Traces | Tipo |
|-------|----------|------|--------|------|
| **Prometheus + Grafana + Loki + Tempo** | Prometheus | Loki | Tempo | Open-source |
| **ELK + Jaeger** | Elasticsearch | Elasticsearch | Jaeger | Open-source |
| **Datadog** | Datadog Metrics | Datadog Logs | Datadog APM | SaaS (pago) |
| **New Relic** | New Relic One | New Relic Logs | New Relic APM | SaaS (pago) |
| **AWS** | CloudWatch Metrics | CloudWatch Logs | X-Ray | Cloud-native |
| **Azure** | Azure Monitor | Azure Monitor Logs | App Insights | Cloud-native |

> **O papel do desenvolvedor**: instrumentar a aplica√ß√£o (Actuator, logs JSON, Micrometer). A infra configura coleta, armazenamento e dashboards.

---

### 7. CI/CD (Conceitual)

#### O Problema: Integra√ß√£o Manual

Sem automa√ß√£o, o fluxo de entrega de software √© assim:

```
Dev termina feature ‚Üí Merge manual ‚Üí "Funciona na minha m√°quina" ‚Üí Build manual no servidor
‚Üí Testes manuais ‚Üí Deploy manual em produ√ß√£o ‚Üí üî• Bug em produ√ß√£o ‚Üí Rollback manual
```

Problemas:
- Merge conflicts acumulados ("merge hell" na sexta-feira)
- Bugs descobertos tarde demais (dias ou semanas depois do commit)
- Deploy √© um evento estressante e arriscado
- Ningu√©m sabe se o c√≥digo est√° deploy√°vel a qualquer momento

---

#### Continuous Integration (CI) ‚Äî Integra√ß√£o Cont√≠nua

**CI** √© a pr√°tica de **integrar c√≥digo frequentemente** (v√°rias vezes ao dia) e **validar automaticamente** cada integra√ß√£o com build e testes.

```mermaid
graph LR
    D1["Dev A<br/>push"] --> R["Reposit√≥rio<br/>(main)"]
    D2["Dev B<br/>push"] --> R
    R -->|"trigger<br/>autom√°tico"| CI["Pipeline CI"]
    CI --> B["Build"]
    B --> TU["Testes<br/>Unit√°rios"]
    TU --> TI["Testes de<br/>Integra√ß√£o"]
    TI --> QA["An√°lise<br/>Est√°tica"]
    QA -->|"‚úÖ Passou"| OK["C√≥digo<br/>Integrado"]
    QA -->|"‚ùå Falhou"| FAIL["Notifica√ß√£o<br/>ao Dev"]
```

**Princ√≠pios do CI:**

| Princ√≠pio | O que significa |
|-----------|----------------|
| Commits frequentes | Integrar ao menos 1x por dia ‚Äî quanto menor o delta, menor o risco |
| Build automatizado | Cada push dispara build + testes sem interven√ß√£o humana |
| Testes automatizados | Testes unit√°rios e de integra√ß√£o rodam a cada commit |
| Feedback r√°pido | Se quebrou, o dev sabe em **minutos**, n√£o dias |
| Main sempre verde | A branch principal deve estar sempre build√°vel e test√°vel |
| Corrigir imediatamente | Se o build quebrou, a prioridade #1 √© consertar |

**O que o CI valida automaticamente:**

```
1. ‚úÖ C√≥digo compila sem erros
2. ‚úÖ Testes unit√°rios passam (JUnit, Mockito)
3. ‚úÖ Testes de integra√ß√£o passam (Testcontainers, MockMvc)
4. ‚úÖ An√°lise est√°tica OK (SonarQube, Checkstyle)
5. ‚úÖ Sem vulnerabilidades conhecidas (OWASP, Snyk)
6. ‚úÖ Cobertura de testes acima do m√≠nimo (ex.: 80%)
```

> **CI n√£o √© uma ferramenta** ‚Äî √© uma **pr√°tica de engenharia**. GitHub Actions, Jenkins e GitLab CI s√£o ferramentas que **implementam** CI.

---

#### Continuous Delivery (CD) ‚Äî Entrega Cont√≠nua

**Continuous Delivery** garante que o c√≥digo est√° **sempre pronto para ser deployado em produ√ß√£o**, mas o deploy final √© feito com **aprova√ß√£o manual** (um bot√£o).

```mermaid
graph LR
    CI["‚úÖ CI Passou"] --> PKG["Empacotar<br/>Artefato"]
    PKG --> STG["Deploy<br/>Staging"]
    STG --> SMOKE["Smoke<br/>Tests"]
    SMOKE --> READY["‚úÖ Pronto<br/>para Prod"]
    READY -->|"üë§ Aprova√ß√£o<br/>manual"| PROD["Deploy<br/>Produ√ß√£o"]
```

**Caracter√≠sticas:**
- O artefato (JAR, imagem Podman) **j√° foi testado** em ambiente similar a produ√ß√£o (staging)
- O deploy em produ√ß√£o √© uma **decis√£o de neg√≥cio**, n√£o t√©cnica
- Pode deployar a qualquer momento com **confian√ßa** ‚Äî sem surpresas
- Rollback √© simples: basta deployar a vers√£o anterior do artefato

---

#### Continuous Deployment ‚Äî Deploy Cont√≠nuo

**Continuous Deployment** vai al√©m: **cada commit que passa no pipeline vai automaticamente para produ√ß√£o**, sem aprova√ß√£o manual.

```mermaid
graph LR
    CI["‚úÖ CI Passou"] --> PKG["Empacotar"]
    PKG --> STG["Deploy<br/>Staging"]
    STG --> SMOKE["Smoke<br/>Tests"]
    SMOKE -->|"autom√°tico"| PROD["Deploy<br/>Produ√ß√£o"]
```

> Empresas como Netflix, Amazon e Google fazem **milhares** de deploys por dia usando Continuous Deployment.

---

#### CI vs. CD ‚Äî Resumo da Diferen√ßa

| Aspecto | CI (Integra√ß√£o Cont√≠nua) | CD (Entrega Cont√≠nua) | CD (Deploy Cont√≠nuo) |
|---------|------------------------|-----------------------|---------------------|
| **Foco** | Integrar e validar c√≥digo | Artefato pronto para produ√ß√£o | Deploy autom√°tico em produ√ß√£o |
| **Trigger** | Cada push/merge | Ap√≥s CI passar | Ap√≥s CI passar |
| **Testes** | Unit√°rios + Integra√ß√£o | + Smoke tests em staging | + Smoke tests em staging |
| **Deploy em produ√ß√£o** | ‚ùå N√£o faz deploy | üë§ Manual (bot√£o) | ü§ñ Autom√°tico |
| **Risco** | Baixo | Baixo | Muito baixo (com bons testes) |
| **Pr√©-requisito** | Testes automatizados | CI funcionando | CD funcionando + alta cobertura |
| **Ado√ß√£o** | Maioria das empresas | Empresas maduras | Empresas avan√ßadas (Netflix, Google) |

```
            CI                         CD                          CD
      Integra√ß√£o Cont√≠nua        Entrega Cont√≠nua           Deploy Cont√≠nuo
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Build + Testes Auto  ‚îÇ‚Üí ‚îÇ Staging + Artefato Pronto‚îÇ‚Üí ‚îÇ Deploy Auto em Prod‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         Cada push                 Aprova√ß√£o manual            100% autom√°tico
```

---

#### O que √© um Pipeline?

Um **pipeline** √© uma sequ√™ncia de **stages (etapas)** automatizadas que o c√≥digo percorre desde o commit at√© a produ√ß√£o. Cada stage tem uma responsabilidade espec√≠fica e, se falhar, **bloqueia as etapas seguintes**.

```mermaid
graph LR
    P["üì§ Push"] --> B["üî® Build"]
    B --> TU["üß™ Testes<br/>Unit√°rios"]
    TU --> TI["üß™ Testes de<br/>Integra√ß√£o"]
    TI --> SA["üîç An√°lise<br/>Est√°tica"]
    SA --> D["üê≥ Podman<br/>Build"]
    D --> R["üì¶ Push<br/>Registry"]
    R --> S["üöÄ Deploy<br/>Staging"]
    S --> SM["‚úÖ Smoke<br/>Tests"]
    SM --> PR["üè≠ Deploy<br/>Produ√ß√£o"]
```

**Stages t√≠picos de um pipeline Java:**

| Stage | O que faz | Ferramentas | Falha se... |
|-------|-----------|-------------|------------|
| **Build** | Compila o c√≥digo e resolve depend√™ncias | Maven, Gradle | Erro de compila√ß√£o |
| **Testes Unit√°rios** | Roda testes isolados (sem infra) | JUnit 5, Mockito | Algum teste falhar |
| **Testes de Integra√ß√£o** | Roda testes com banco/fila reais | Testcontainers, MockMvc | Integra√ß√£o falhar |
| **An√°lise Est√°tica** | Verifica qualidade e vulnerabilidades | SonarQube, Checkstyle, Snyk | Code smell, CVE cr√≠tico |
| **Podman Build** | Cria imagem Podman da aplica√ß√£o | Podman, Buildpacks | Containerfile com erro |
| **Push Registry** | Publica imagem no registry | Podman Hub, ECR, ACR, GCR | Autentica√ß√£o falhar |
| **Deploy Staging** | Deploya em ambiente de testes | Kubernetes, ECS, Azure App Service | Health check falhar |
| **Smoke Tests** | Testes b√°sicos em staging | REST Client, Newman, k6 | Endpoint n√£o responder |
| **Deploy Produ√ß√£o** | Deploya em produ√ß√£o | Kubernetes, ECS | Health check falhar |

**Conceitos importantes do pipeline:**

| Conceito | Significado |
|----------|------------|
| **Stage** | Uma etapa do pipeline (Build, Test, Deploy) |
| **Job** | Uma unidade de trabalho dentro de um stage |
| **Artifact** | Arquivo gerado por um stage e usado pelo pr√≥ximo (JAR, imagem Podman) |
| **Runner/Agent** | M√°quina que executa o pipeline (GitHub-hosted, self-hosted) |
| **Trigger** | Evento que inicia o pipeline (push, merge request, schedule) |
| **Gate** | Aprova√ß√£o manual necess√°ria para prosseguir (ex.: deploy em produ√ß√£o) |

---

#### Ferramentas de CI/CD

| Ferramenta | Tipo | Onde roda | Arquivo de config |
|------------|------|-----------|-------------------|
| **GitHub Actions** | SaaS | GitHub | `.github/workflows/*.yml` |
| **GitLab CI** | SaaS / Self-hosted | GitLab | `.gitlab-ci.yml` |
| **Jenkins** | Self-hosted | Servidor pr√≥prio | `Jenkinsfile` |
| **Azure DevOps** | SaaS | Azure | `azure-pipelines.yml` |
| **CircleCI** | SaaS | CircleCI | `.circleci/config.yml` |
| **AWS CodePipeline** | SaaS | AWS | Console / CloudFormation |

#### GitHub Actions ‚Äî Exemplo de Pipeline

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  # Stage 1: Build + Testes
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Java 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Build e Testes
        run: mvn clean verify

      - name: Upload Artefato
        uses: actions/upload-artifact@v4
        with:
          name: app-jar
          path: target/*.jar

  # Stage 2: Podman Build + Push
  podman:
    needs: build-and-test   # s√≥ roda se o stage anterior passou
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'  # s√≥ na main
    steps:
      - uses: actions/checkout@v4

      - name: Build Podman Image
        run: podman build -t myapp:${{ github.sha }} .

      - name: Push to Registry
        run: podman push registry/myapp:${{ github.sha }}

  # Stage 3: Deploy (com aprova√ß√£o manual = Continuous Delivery)
  deploy:
    needs: podman
    runs-on: ubuntu-latest
    environment: production   # requer aprova√ß√£o manual no GitHub
    steps:
      - name: Deploy to Production
        run: echo "Deploying version ${{ github.sha }}"
```

> **Regra de ouro**: c√≥digo que n√£o passa no pipeline **n√£o vai pra produ√ß√£o**.

> **Na pr√°tica**: a maioria das empresas come√ßa com CI (build + testes autom√°ticos) e evolui para Continuous Delivery. Continuous Deployment exige maturidade em testes e monitoramento.

---

## üì¶ Projetos do Dia

### `07-podman-actuator-demo` (Projeto Completo ‚Äî Demonstra√ß√£o)

> API de Produtos containerizada com Actuator, logs estruturados e observabilidade ‚Äî tudo subindo com `podman compose up`.

Projeto completo demonstrando os conceitos:
- `Containerfile` multi-stage build otimizado (~80MB com JRE Alpine)
- `.containerignore` configurado
- `podman-compose.yml` com: app Spring Boot, PostgreSQL, RabbitMQ, Redis ‚Äî todos com health checks
- Spring Actuator expondo `/health`, `/metrics`, `/info` com detalhes
- Custom Health Indicator verificando conectividade com RabbitMQ
- `logback-spring.xml` com `LogstashEncoder` gerando logs em JSON
- MDC Filter adicionando `traceId`, `method`, `uri` em cada log
- Profile `default/dev` (logs texto) vs. `prod` (logs JSON) no Logback

**Porta**: `8080`

### `07-employee-api-production` (Exerc√≠cio ‚Äî TODOs 1-7)

> Containerizar a API de Funcion√°rios e adicionar observabilidade para produ√ß√£o.

**O que j√° vem pronto:** `Containerfile` b√°sico n√£o otimizado, `podman-compose.yml` com apenas PostgreSQL, `logback-spring.xml` com logs em texto, depend√™ncia do Actuator sem endpoints expostos.

**TODOs**: 7 tarefas cobrindo Containerfile multi-stage, .containerignore, Podman Compose completo, Actuator, Custom HealthIndicator, Logs JSON + MDC e logging contextual.

**Porta**: `8092`

---

## üìé Slides

| Slide | T√≥pico |
|-------|--------|
| [slide-01](slide-01.md) | Abertura e Recap do Dia 6 |
| [slide-02](slide-02.md) | Podman ‚Äî Containerfile e Conceitos |
| [slide-03](slide-03.md) | Multi-stage Build e .containerignore |
| [slide-04](slide-04.md) | Podman Compose ‚Äî Orquestrando a Stack |
| [slide-05](slide-05.md) | Spring Actuator ‚Äî Health, Metrics, Info |
| [slide-06](slide-06.md) | Logs Estruturados ‚Äî Logback JSON |
| [slide-07](slide-07.md) | MDC ‚Äî Mapped Diagnostic Context |
| [slide-08](slide-08.md) | Observabilidade ‚Äî Os 3 Pilares |
| [slide-09](slide-09.md) | CI/CD ‚Äî Conceitos e GitHub Actions |
| [slide-10](slide-10.md) | Walkthrough ‚Äî 07-podman-actuator-demo |
| [slide-11](slide-11.md) | Exerc√≠cio ‚Äî TODOs 1-2 (Containerfile) |
| [slide-12](slide-12.md) | Exerc√≠cio ‚Äî TODO 3 (Podman Compose) |
| [slide-13](slide-13.md) | Exerc√≠cio ‚Äî TODOs 4-5 (Actuator + HealthIndicator) |
| [slide-14](slide-14.md) | Exerc√≠cio ‚Äî TODO 6 (Logs JSON + MDC) |
| [slide-15](slide-15.md) | Exerc√≠cio ‚Äî TODO 7 (Logging Contextual) |
| [slide-16](slide-16.md) | Review e Q&A |
